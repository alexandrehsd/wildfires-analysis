---
title: "WildFires Analysis - Exploratory Data Analysis"
output: html_notebook
---

```{r warning=FALSE}
# Loading packages
library(pryr) # Memory usage information
library(lubridate) # date manipulation
library(dplyr) # data manipulation 
library(ggplot2) # graphics
library(plotly)
library(stringr)
library(stringi) # remove diacritics
library(ggfortify)
library(rjson)
library(nasapower)
```


There are 4 csv files containing data about the fires of all ocurrences around all brazilian territory. Each file has data between 1st Sept to 30th Sept of each year from 2015 to 2019.

```{r}
temp <- list.files(path = "./database" ,pattern = "*.csv")
myfiles = lapply(paste0("./database/",temp), read.csv)

nrecords <- lapply(myfiles, nrow)

data <- bind_rows(myfiles)
names(data)

# As we have many data records, we'll be working with a small subset of it
df <- data[sample(nrow(data), 0.1*totalNo), ]
totalNo <- nrow(df)

object_size(df)
```

there are 820929 observations in our dataset which sums up to 66.8 MB of storaged data.

```{r}
head(df)
```

```{r}
str(df)
```

Aparentemente, A coluna de área industrial e FRP tem poucas entradas não nulas

```{r}
# paste("Percentage of NAs entries on `FRP` =",
#       100*sum(is.na(df$frp))/totalNo)

wetDays <- df$diasemchuva <= 10
dryDays <- df$diasemchuva > 10
noWeatherInfo <- is.na(df$diasemchuva)

paste("Percentage of NAs entries on `diasemchuva` =",
      round(100*(sum(noWeatherInfo))/totalNo,2))

paste("Percentage of records with less than (or equal to) 10 days of no rain =",
      round(100*(sum(wetDays, na.rm = T))/totalNo,2))

paste("Percentage of records with more than 10 days of no rain =",
      round(100*(sum(dryDays, na.rm = T))/totalNo,2))
```

By the last results, it is possible that the number of days with no rain have a huge impact over the fires triggers.

we can also investigate another columns that have either redundant data or not useful data.

```{r}
levels(df$pais)
df$pais <- NULL

object_size(df)
```

By looking at the structure of our dataframe, it becomes clear that the `Datahora` is a datetime object not a Factor.

```{r}
df$datahora <- ymd_hms(str_replace_all(df$datahora,"/","-"))

levels(df$bioma)
```

We have 6 distincts biomas on our dataset. Perhaps, by knowing how is the distribution of fires among different biomas, we can refine our research.

```{r}
counts <- table(df$bioma)
counts

proportions <- 100*counts / sum(counts)
proportions
```

As we can see, Amazonia represents around half of our dataset. In addition, the number of fire occurrences is very much like the proportion of land that each bioma has in brazilian territory.

-------------------------- Visualisations -----------------------------

```{r}
temp <- df %>% 
          mutate(ano = year(datahora),
                 mes = month(datahora))

View(temp)
```


```{r, fig.width = 4, fig.height= 3}
ggplot(df) + 
    geom_bar(aes(x = bioma, y = 100*..prop.., group = 1)) +
    coord_flip()
```


```{r}

df %>% 
  mutate(year_month = str_c(format(datahora, "%y/%m"))) %>% 
  group_by(year_month, bioma) %>% 
  summarise(n_fires = n()) %>% 
  ggplot(aes(x = year_month, y = n_fires/1000)) +
  geom_bar(aes(fill = bioma), stat = 'identity') + 
    labs(x = '', y = 'Number of wildfires (thousands)', title = 'Brazilian Wildfires by Year') +
    coord_flip()

```

In order to plot the number of fires by state, we must do some data wrangling to put the data in the desired format.

```{r}

is.odd <- function(x) x %% 2 != 0
is.even <- function(x) x %% 2 == 0

geo_data <- fromJSON(file = "./geo_data/geo_data.json")

maps_df <- list()
  for (i in 1:length(geo_data$features)) {
    coordinates <- unlist(geo_data$features[[i]]$geometry$coordinates[[1]])
    long <- coordinates[is.odd(seq_along(coordinates))]
    lat <-  coordinates[is.even(seq_along(coordinates))]
    
    if(length(long) != length(lat)){
      stop("Wrong subset of coordinate vector", call. = FALSE)
    }
    
    geo_length <- length(long)
    
    estado <- toupper(geo_data$features[[i]]$properties$name)
    codigo <- as.integer(geo_data$features[[i]]$properties$codigo_ibg)
    regiao <- as.integer(geo_data$features[[i]]$properties$regiao_id)
    
    maps_df[[i]] <- as_tibble(
      list(
        estado = rep(stri_trans_general(estado,"Latin-ASCII"), geo_length),
        codigo = rep(codigo, geo_length),
        regiao = rep(regiao, geo_length),
        longitude = long,
        latitude = lat
      )
    )
  }
  
  map_df <- bind_rows(maps_df)
```


```{r}
# the `estado` column of the map dataframe is a character, so in order
# to avoid coertion from factor to character, let's convert it explicitly
df$estado <- as.character(df$estado)
```

```{r}
df %>% 
  select(estado) %>% 
  group_by(estado) %>% 
  summarise(n = n()) %>% 
  right_join(map_df, by = 'estado') %>% 
  ggplot(aes(x = longitude, y = latitude, group = codigo, fill = n/1000)) + 
    geom_polygon() + 
    geom_path(color = 'white') + 
    scale_fill_continuous(low = "orange", 
                          high = "darkred",
                          name = 'Number of fires\n(thousands)'
                          ) 
```

```{r}
df %>% 
  select(estado, datahora) %>% 
  mutate(ano = year(datahora)) %>% 
  group_by(estado, ano) %>% 
  summarise(n = n()) %>% 
  right_join(map_df, by = 'estado') %>% 
  ggplot(aes(x = longitude, y = latitude, group = codigo, fill = n/1000)) + 
    geom_polygon() +
    facet_wrap(~ano) +
    geom_path(color = 'white') + 
    scale_fill_continuous(low = "orange", 
                          high = "darkred",
                          name = 'Number of fires\n(thousands)'
                          ) 
```

```{r}
df %>% 
  group_by(estado) %>% 
  ggplot(aes(x = factor(estado))) +
    geom_bar() +
    coord_flip()
```


```{r}
df %>% 
  mutate(ano = year(datahora)) %>% 
  group_by(estado, ano) %>% 
  ggplot(aes(x = factor(estado), fill = factor(ano))) +
    geom_bar() +
    coord_flip()
```

O dataframe original não tem informações sobre macro regiões. Utilizando o data frame de mapas, podemos obter esta informação.

```{r}

regionsList <- list()
n_reg <- length(unique(map_df$regiao))
regions <- unique(map_df$regiao)

for(i in 1:n_reg){
  temp <- map_df %>% filter(regiao == regions[i])
  
  states <- unique(temp$estado)
  regionsList[[i]] <- states
}

names(regionsList) <- c("NORTE", "NORDESTE", "SUDESTE", "CENTRO-OESTE", "SUL")

for(i in 1:n_reg){
  df$macroRegiao[df$estado %in% regionsList[[i]]] <- names(regionsList)[i]
}

```

From NasaPower API we can obtain useful data for about 146 weather and climate parameters, such as:

Relative humidty (at two meters)
Temperature (at two meters)
Precipitation (mm)
Maximum/Minimum Monthly Difference From Monthly Averaged All Sky Insolation
Wind Speed 

geographical data are provided at the resolution of 1/2 arc degree longitude by 1/2 arc degree latitude. for more detailed info go to https://power.larc.nasa.gov/documents/POWER_Data_v9_methodology.pdf

Another useful resource can be found at https://earthobservatory.nasa.gov/images/145464/fires-in-brazil

Also in https://www.globalfiredata.org/data.html we can find data such as carbon emissions and dry matter emissions.





